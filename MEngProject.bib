Automatically generated by Mendeley Desktop 1.15.2
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Abouelhoda2012,
abstract = {ABSTRACT: BACKGROUND: Over the past decade the workflow system paradigm has evolved as an efficient and user-friendly approach for developing complex bioinformatics applications. Two popular workflow systems that have gained acceptance by the bioinformatics community are Taverna and Galaxy. Each system has a large user-base and supports an ever-growing repository of application workflows. However, workflows developed for one system cannot be imported and executed easily on the other. The lack of interoperability is due to differences in the models of computation, workflow languages, and system architectures of both systems. This lack of interoperability limits sharing of workflows between the user communities and leads to duplication of development efforts. RESULTS: In this paper, we present Tavaxy, a stand-alone system for creating and executing workflows based on using an extensible set of re-usable workflow patterns. Tavaxy offers a set of new features that simplify and enhance the development of sequence analysis applications: It also allows the integration of existing Taverna and Galaxy workflows in a single environment, and supports the use of cloud computing capabilities. The integration of existing Taverna and Galaxy workflows is supported seamlessly at both run-time and design-time levels, based on the concepts of hierarchical workflows and workflow patterns. The use of cloud computing in Tavaxy is flexible, where the users can either instantiate the whole system on the cloud, or delegate the execution of certain sub-workflows to the cloud infrastructure. CONCLUSIONS: Tavaxy reduces the workflow development cycle by introducing the use of workflow patterns to simplify workflow creation. It enables the re-use and integration of existing (sub-) workflows from Taverna and Galaxy, and allows the creation of hybrid workflows. Its additional features exploit recent advances in high performance cloud computing to cope with the increasing data size and complexity of analysis. The system can be accessed either through a cloud-enabled web-interface or downloaded and installed to run within the user's local environment. All resources related to Tavaxy are available at http://www.tavaxy.org.},
author = {Abouelhoda, Mohamed and Issa, Shadi a and Ghanem, Moustafa},
doi = {10.1186/1471-2105-13-77},
file = {:Users/adrian/Work/project/papers/Tavaxy - Integrating Taverna and Galaxy workflows with cloud computing support.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$n1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
number = {1},
pages = {77},
pmid = {22559942},
title = {{Tavaxy: Integrating Taverna and Galaxy workflows with cloud computing support.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22559942},
volume = {13},
year = {2012}
}
@article{Deelman2004,
abstract = {In this paper we describe the Pegasus system that can map complex workflows onto the Grid. Pegasus takes an abstract description of a workflow and finds the appropriate data and Grid resources to execute the workflow. Pegasus is being released as part of the GriPhyN Virtual Data Toolkit and has been used in a variety of applications ranging from astronomy, biology, gravitational-wave science, and high-energy physics. A deferred planning mode of Pegasus is also introduced.},
author = {Deelman, Ewa and Blythe, James and Gil, Yolanda and Kesselman, Carl},
doi = {10.1007/978-3-540-28642-4{\_}2},
file = {:Users/adrian/Work/project/papers/Pegasus - Mapping Scientific Workflows onto the Grid.pdf:pdf},
isbn = {978-3-540-22888-2},
issn = {1541-1672},
journal = {Grid Computing},
pages = {131--140},
pmid = {8425240},
title = {{Pegasus: Mapping scientific workflows onto the grid}},
url = {http://www.springerlink.com/index/95rj5e2fgqqpkaha.pdf},
volume = {3165/2004},
year = {2004}
}
@article{Wu2015,
author = {Wu, Fuhui and Wu, Qingbo and Tan, Yusong},
doi = {10.1007/s11227-015-1438-4},
file = {:Users/adrian/Work/project/papers/Workflow scheduling in cloud - a survey.pdf:pdf},
isbn = {978-1-4799-5467-4},
issn = {1573-0484},
journal = {The Journal of Supercomputing},
keywords = {Cloud computing,Data-intensive workflow scheduling,Hybrid environment,QoS constrained scheduling,Robust scheduling,Workflow scheduling,Workflow-as-a-service,cloud computing,data-intensive,hybrid environment,qos constrained scheduling,robust scheduling,workflow scheduling,workflow-as-a-service},
month = {may},
number = {9},
pages = {3373--3418},
title = {{Workflow scheduling in cloud : a survey}},
url = {"http://dx.doi.org/10.1007/s11227-015-1438-4},
volume = {71},
year = {2015}
}
@misc{Galaxy,
author = {{Galaxy Contributors}},
title = {{The Galaxy Project: Online bioinformatics analysis for everyone}},
url = {https://galaxyproject.org/},
urldate = {2016-01-24}
}
@article{Curcin2008,
abstract = {The past decade has witnessed a growing trend in designing and using workflow systems with a focus on supporting the scientific research process in bioinformatics and other areas of life sciences. The aim of these systems is mainly to simplify access, control and orchestration of remote distributed scientific data sets using remote computational resources, such as EBI web services. In this paper we present the state of the art in the field by reviewing six such systems: Discovery Net, Taverna, Triana, Kepler, Yawl and BPEL. We provide a high-level framework for comparing the systems based on their control flow and data flow properties with a view of both informing future research in the area by academic researchers and facilitating the selection of the most appropriate system for a specific application task by practitioners.},
author = {Curcin, V. and Ghanem, M.},
doi = {10.1109/CIBEC.2008.4786077},
file = {:Users/adrian/Library/Application Support/Mendeley Desktop/Downloaded/Curcin, Ghanem - 2008 - Scientific workflow systems - can one size fit all.pdf:pdf},
isbn = {978-1-4244-2694-2},
issn = {1424426944},
journal = {2008 Cairo International Biomedical Engineering Conference},
keywords = {Bioinformatics,Business,Control systems,Data analysis,Data mining,Distributed computing,EBI Web services,Educational institutions,Grid computing,Testing,Web services,bioinformatics,control flow,data flow,distributed databases,remote computational resources,remote distributed scientific data sets,scientific workflow systems,workflow systems},
pages = {1--9},
title = {{Scientific workflow systems - can one size fit all?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4786077},
year = {2008}
}
@article{Reuillon2013,
abstract = {Complex-systems describe multiple levels of collective structure and organization. In such systems, the emergence of global behaviour from local interactions is generally studied through large scale experiments on numerical models. This analysis generates important computation loads which require the use of multi-core servers, clusters or grid computing. Dealing with such large scale executions is especially challenging for modellers who do not possess the theoretical and methodological skills required to take advantage of high performance computing environments. That is why we have designed a cloud approach for model experimentation. This approach has been implemented in OpenMOLE (Open MOdeL Experiment) as a Domain Specific Language (DSL) that leverages the naturally parallel aspect of model experiments. The OpenMOLE DSL has been designed to explore user-supplied models. It delegates transparently their numerous executions to remote execution environment. From a user perspective, those environments are viewed as services providing computing power, therefore no technical detail is ever exposed. This paper presents the OpenMOLE DSL through the example of a toy model exploration and through the automated calibration of a real-world complex-system model in the field of geography. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Reuillon, Romain and Leclaire, Mathieu and Rey-Coyrehourcq, Sebastien},
doi = {10.1016/j.future.2013.05.003},
file = {:Users/adrian/Work/project/papers/OpenMOLE, a workflow engine specifically tailored for the distributed exploration of simulation models.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud computing,Complex-systems,Distributed computing,Model exploration,Workflow},
number = {8},
pages = {1981--1990},
title = {{OpenMOLE, a workflow engine specifically tailored for the distributed exploration of simulation models}},
volume = {29},
year = {2013}
}
@misc{Kepler,
author = {{Kepler Contributors}},
title = {{The Kepler Project}},
url = {https://kepler-project.org/},
urldate = {2016-01-24}
}
@misc{BioVeL,
author = {{BioVeL Contributors}},
title = {{BioVeL}},
url = {https://www.biovel.eu/},
urldate = {2016-01-24}
}
@misc{Torque,
author = {{Adaptive Computing}},
keywords = {Adaptive Computing},
title = {{TORQUE Resource Manager}},
url = {http://www.adaptivecomputing.com/products/open-source/torque/},
urldate = {2016-01-24}
}
@article{Deelman2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Deelman, Ewa},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/adrian/Work/project/papers/Pegasus, a Workflow Management System for Science Automation.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {pegasus,scientific workflow,workflow management system},
pages = {160},
pmid = {25246403},
title = {{Pegasus, a Workflow Management System for Large-Scale Science}},
year = {2013}
}
@article{Korambath2014,
abstract = {21st Century Smart Manufacturing (SM) is manufacturing in which all information is available when it is needed, where it is needed, and in the form it is most useful [1,2] to drive optimal actions and responses. The 21st Century SM enterprise is data driven, knowledge enabled, and model rich with visibility across the enterprise (internal and external) such that all operating actions are determined and executed proactively by applying the best information and a wide range of performance metrics. SM also encompasses the sophisticated practice of generating and applying data-driven Manufacturing Intelligence throughout the lifecycle of design, engineering, planning and production. Workflow is foundational in orchestrating dynamic, adaptive, actionable decision-making through the contextualization and understanding of data. Pervasive deployment of architecturally consistent workflow applications creates the enterprise environment for manufacturing intelligence. Workflow as a Service (WfaaS) software allows task orchestration and facilitates workflow services and manage environment to integrate interrelated task components. Apps, and toolkits are required to assemble customized SM applications on a common, standards based workflow architecture and deploy on infrastructure that is accessible by small, medium, and large companies. Incorporating dynamic decision-making steps through contextualization of real-time data requires scientific workflow software such as Kepler. By combining workflow, private cloud computing and web services technologies, we built a prototype test bed to test a furnace temperature control model. © The Authors. Published by Elsevier B.V.},
author = {Korambath, Prakashan and Wang, Jianwu and Kumar, Ankur and Hochstein, Lorin and Schott, Brian and Graybill, Robert and Baldea, Michael and Davis, Jim},
doi = {10.1016/j.procs.2014.05.210},
file = {:Users/adrian/Work/project/papers/Deploying Kepler Workflows as Services on a Cloud Infrastructure for Smart Manufacturing.pdf:pdf},
isbn = {1877-0509},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Cloud computing,Kepler workflows,Smart manufacturing,Workflow as a service},
pages = {2254--2259},
publisher = {Elsevier Masson SAS},
title = {{Deploying kepler workflows as services on a cloud infrastructure for smart manufacturing}},
url = {http://dx.doi.org/10.1016/j.procs.2014.05.210},
volume = {29},
year = {2014}
}
@misc{OpenMOLE,
author = {{OpenMOLE Contributors}},
keywords = {Cluster,Data Parallelism,Design of Experiment,Distributed Computing,Grid,Model Exploration,Parameter Tuning,Scientific Workflow Engine,Sensitivity Analysis},
title = {{OpenMOLE}},
url = {http://www.openmole.org/},
urldate = {2016-01-24}
}
@misc{SLURM,
author = {{SLURM Contributors}},
keywords = {Linux clusters,SLURM,Simple Linux Utility for Resource Management,high-performance computing,resource management},
title = {{Simple Linux Utility for Resource Management}},
url = {http://slurm.schedmd.com/},
urldate = {2016-01-24}
}
@misc{StarCluster,
author = {{StarCluster Contributors}},
title = {{STAR: Cluster}},
url = {http://star.mit.edu/cluster/},
urldate = {2016-01-22}
}
@article{Goble2009,
abstract = {Increasingly, scientific breakthroughs will be powered by advanced computing capabilities that help researchers manipulate and explore massive datasets.  The speed at which any given scientific discipline advances will depend on how well its researchers collaborate with one another, and with technologists, in areas of eScience such as databases, workflow management, visualization, and cloud computing technologies.  In The Fourth Paradigm: Data-Intensive Scientific Discovery, the collection of essays expands on the vision of pioneering computer scientist Jim Gray for a new, fourth paradigm of discovery based on data-intensive science and offers insights into how it can be fully realized.},
author = {Goble, Carole and {De Roure}, David},
file = {:Users/adrian/Work/project/papers/The Impact of Workflow Tools on Data-centric Research.pdf:pdf},
isbn = {978-0-9825442-0-4},
journal = {The Fourth Paradigm: Data-Intensive Scientific Discovery},
keywords = {computability,computational methods,computational science,data intensity,data mining,eScience,ensemble,information theory,knowledge acquisition,knowledge-base,modeling,pattern recognition,scientific discovery},
pages = {137--145},
title = {{The Impact of Workflow Tools on Data-centric Research}},
url = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/default.aspx},
year = {2009}
}
@misc{Yapa,
author = {{OpenMOLE Contributors}},
title = {{Yapa}},
url = {https://github.com/openmole/yapa},
urldate = {2016-01-24}
}
@article{Pierce2014a,
abstract = {We present an overview of the Apache Airavata Application Programming Interface (API), describe the design choices and implementation details, and describe how API methods map to the UltraScan Science Gateway use case. The Airavata API is designed to standardize access to Airavata services that provide gateways with scientific application metadata and execution management. The API also represents an important milestone in the development of Science Gateway Platform as a Service (SciGaP), a hosted, multi-tenanted gateway service based on open source Airavata software. The UltraScan gateway is a production XSEDE gateway that has been using Airavata services for over three years through customized interfaces and represents a stringent test of the API design and implementation.},
author = {Pierce, Marlon and Marru, Suresh and Demeler, Borries and Singh, Raminderjeet and Gorbet, Gary},
doi = {10.1109/GCE.2014.15},
file = {:Users/adrian/Work/project/papers/The Apache Airavata Application Programming Interface - Overview and Evaluation with the UltraScan Science Gateway.pdf:pdf},
isbn = {978-1-4799-7030-8},
journal = {2014 9th Gateway Computing Environments Workshop},
keywords = {Catalogs,Communities,Data models,Educational institutions,Logic gates,Science gateways,Servers,Software,application programming interfac,application programming interface design,cloud computing,cyberinfrastructure},
number = {November},
pages = {25--29},
title = {{The Apache Airavata Application Programming Interface: Overview and Evaluation with the UltraScan Science Gateway}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7021845},
year = {2014}
}
@misc{Condor,
author = {{HTCondor Contributors}},
title = {{HTCondor}},
url = {https://research.cs.wisc.edu/htcondor/},
urldate = {2016-01-24}
}
@article{Wang2012,
author = {Wang, Jianwu and Altintas, Ilkay},
doi = {10.1016/j.procs.2012.04.179},
file = {:Users/adrian/Work/project/papers/Early Cloud Experiences with the Kepler Scientific Workflow System.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {amazon ec2,bioinformatics,cloud computing,data-intensive,scientific workflows},
pages = {1630--1634},
title = {{Early Cloud Experiences with the Kepler Scientific Workflow System}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050912003006},
volume = {9},
year = {2012}
}
@misc{Pegasus,
author = {{Pegasus Contributors}},
title = {{Pegasus}},
url = {http://pegasus.isi.edu/},
urldate = {2016-01-24}
}
@misc{OpenMOLEMarketplace,
author = {{OpenMOLE Contributors}},
title = {{OpenMOLE Marketplace}},
url = {https://github.com/openmole/openmole-market},
urldate = {2016-01-24}
}
@misc{EGI,
author = {{EGI Contributors}},
title = {{EGI - European Grid Infrastructure}},
url = {http://www.egi.eu/},
urldate = {2016-01-24}
}
@misc{AmazonEBS,
author = {Amazon},
title = {{Amazon Elastic Block Store (EBS) – AWS Block Storage}},
url = {https://aws.amazon.com/ebs/},
urldate = {2016-01-25}
}
@article{Afgan2010,
abstract = {Widespread adoption of high-throughput sequencing has greatly increased the scale and sophistication of computational infrastructure needed to perform genomic research. An alternative to building and maintaining local infrastructure is "cloud computing", which, in principle, offers on demand access to flexible computational infrastructure. However, cloud computing resources are not yet suitable for immediate "as is" use by experimental biologists.},
author = {Afgan, Enis and Baker, Dannon and Coraor, Nate and Chapman, Brad and Nekrutenko, Anton and Taylor, James},
doi = {10.1186/1471-2105-11-S12-S4},
file = {:Users/adrian/Work/project/papers/Galaxy CloudMan - delivering cloud compute clusters.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$n1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
number = {Suppl 12},
pages = {S4},
pmid = {21210983},
title = {{Galaxy CloudMan: delivering cloud compute clusters}},
url = {http://www.biomedcentral.com/1471-2105/11/S12/S4},
volume = {11 Suppl 1},
year = {2010}
}
@misc{OAR,
author = {{OAR Contributors}},
keywords = {start},
title = {{OAR}},
url = {https://oar.imag.fr/},
urldate = {2016-01-24}
}
@article{Passerat2016,
author = {Passerat-Palmbach, Jonathan and Rueckert, Daniel and Reuillon, Romain},
file = {:Users/adrian/Work/project/papers/GridScale - distributed computing for applications running in the Java Virtual Machine.pdf:pdf},
title = {{GridScale: distributed computing for applications running in the Java Virtual Machine}},
year = {2016}
}
@article{Reuillon2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.04182v1},
author = {Reuillon, Romain and Passerat-Palmbach, Jonathan},
doi = {10.1109/HPCSim.2015.7237015},
eprint = {arXiv:1506.04182v1},
file = {:Users/adrian/Work/project/papers/Model Exploration Using OpenMOLE - a workflow engine for large scale distributed design of experiments and parameter tuning.pdf:pdf},
isbn = {9781467378123},
journal = {IEEE High Performance Computing and Simulation conference 2015.},
title = {{Model Exploration Using OpenMOLE a workflow engine for large scale distributed design of experiments and parameter tuning}},
year = {2015}
}
@misc{Giacinto,
author = {Donvito, Giacinto},
title = {{BioVeL: Taverna Workflows on distributed grid computing for Biodiversity}},
url = {https://indico.egi.eu/indico/event/1222/session/34/contribution/53/material/slides/0.pdf},
urldate = {2016-01-24}
}
@article{Koteska,
author = {Koteska, Bojana and Jakimovski, Boro and Mishev, Anastas},
file = {:Users/adrian/Work/project/papers/Building Scientific Workflows on the Grid - A Comparison between OpenMole and Taverna.pdf:pdf},
keywords = {-scientific workflow,4,are structured based on,control and data dependencies,grid,java,openmole,scientific process where tasks,taverna,the goal of scientific,the main purpose of,the scientific workflow is,their,to automate the},
title = {{Building Scientific Workflows on the Grid : A Comparison between OpenMole and Taverna}}
}
@article{Ludascher2006,
author = {Lud{\"{a}}scher, Bertram and Altintas, Ilkay and Berkley, Chad and Higgins, Dan and Jaeger, Efrat and Jones, Matthew and Lee, Edward A. and Tao, Jing and Zhao, Yang},
doi = {10.1002/cpe.994},
file = {:Users/adrian/Work/project/papers/Scientific workflow management and the Kepler system.pdf:pdf},
issn = {1532-0626},
journal = {Concurrency and Computation: Practice and Experience},
keywords = {bertram lud,correspondence to,dataflow networks,grid workflows,ments,problem-solving environ-,scientific data management,scientific workflows},
number = {10},
pages = {1039--1065},
title = {{Scientific workflow management and the Kepler system}},
url = {http://doi.wiley.com/10.1002/cpe.994},
volume = {18},
year = {2006}
}
@article{Reuillon2010,
abstract = {In this paper we present {\{}OpenMOLE{\}}, a scientific framework providing a virtualized runtime environment for distributed computing. Current distributed execution systems do not hide the hardware and software heterogeneity of computing and data resources whereas {\{}OpenMOLE{\}} provides generic services to develop distributed scientific algorithms independently from the execution environment architecture. {\{}OpenMOLE{\}} uses abstraction layers to delegate computing tasks with the same high level interface for the major underlying architectures: local processors, batch systems, computational grids, Internet computing and cloud computing. The file access abstraction layer is another key feature helping a generic usage of the computation power provided by grids and clusters. The {\{}OpenMOLE{\}} framework has been tested with the exploration of a bacterial biofilm simulation with an individual-based model.},
author = {Reuillon, Romain and Chuffart, Florent and Leclaire, Mathieu and Faure, Thierry and Dumoulin, Nicolas and Hill, David},
doi = {10.1109/HPCS.2010.5547155},
file = {:Users/adrian/Work/project/papers/Declarative tak delegation in OpenMOLE.pdf:pdf},
isbn = {9781424468300},
journal = {High Performance Computing and Simulation (HPCS), 2010 International Conference on},
keywords = {2,design of computer experiments,distributed simulation,ex-,exploration,grid computing,high perfomance computing,related work in distributed,task delegation},
pages = {55--62},
title = {{Declarative task delegation in OpenMOLE}},
year = {2010}
}
@misc{S3,
author = {Amazon},
title = {{Amazon Simple Storage Service (S3) - Object Storage}},
url = {https://aws.amazon.com/s3/},
urldate = {2016-01-25}
}
@inproceedings{Pierce2014,
abstract = {This paper provides an overview of the Apache Airavata software system for science gateways. Gateways use Airavata to manage application and workflow executions on a range of backend resources (grids, computing clouds, and local clusters). Airavata's design goal is to provide component abstractions for major tasks required to provide gateway application management. Components are not directly accessed but are instead exposed through a client Application Programming Interface. This design allows gateway developers to take full advantage of Airavata's capabilities, and Airavata developers (including those interested in middleware research) to modify Airavata's implementations and behavior. This is particularly important as Airavata evolves to become a scalable, elastic "platform as a service" for science gateways. We illustrate the capabilities of Airavata through the discussion of usage vignettes. As an Apache Software Foundation project, Airavata's open community governance model is as important as its software base. We discuss how this works within Airavata and how it may be applicable to other distributed computing infrastructure and cyber infrastructure efforts. © 2014 IEEE.},
author = {Pierce, Marlon and Marru, Suresh and Gunathilake, Lahiru and Kanewala, Thejaka Amila and Singh, Raminder and Wijeratne, Saminda and Wimalasena, Chathuri and Herath, Chathura and Chinthaka, Eran and Mattmann, Chris and Slominski, Aleksander and Tangchaisin, Patanachai},
booktitle = {2014 6th International Workshop on Science Gateways},
doi = {10.1109/IWSG.2014.15},
file = {:Users/adrian/Work/project/papers/Apache Airavata - Design and Directions of a Science Gateway Framework.pdf:pdf},
isbn = {978-1-4799-5819-1},
keywords = {cyberinfrastructure,distributed computing infrastructure,open source software,science gateways},
month = {jun},
pages = {48--54},
publisher = {IEEE},
title = {{Apache Airavata: Design and Directions of a Science Gateway Framework}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84906976392{\&}partnerID=tZOtx3y1},
year = {2014}
}
@article{Goecks2010,
abstract = {Increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. Galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. Galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. Galaxy Pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis.},
author = {Goecks, Jeremy and Nekrutenko, Anton and Taylor, James},
doi = {10.1186/gb-2010-11-8-r86},
file = {:Users/adrian/Work/project/papers/Galaxy - a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences.pdf:pdf},
isbn = {1465-6914 (Electronic)$\backslash$r1465-6906 (Linking)},
issn = {1465-6906},
journal = {Genome biology},
number = {8},
pages = {R86},
pmid = {20738864},
title = {{Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences.}},
volume = {11},
year = {2010}
}
@misc{caGrid,
author = {caGrid Contributors},
title = {{caGrid}},
url = {http://www.cagrid.org/display/cagridhome/Home},
urldate = {2016-01-24}
}
@misc{Airavata,
author = {{Apache Airavata Contributors}},
title = {{Apache Airavata}},
url = {https://airavata.apache.org/},
urldate = {2016-01-24}
}
@misc{SGE,
annote = {Previously known as Sun Grid Engine or Oracle Grid Engine.},
author = {{Open Grid Engine Contributors}},
title = {{Open Grid Engine}},
url = {http://sourceforge.net/projects/gridscheduler/},
urldate = {2016-01-24}
}
@article{Wolstencroft2013,
author = {Wolstencroft, K. and Haines, R. and Fellows, D. and Williams, A. and Withers, D. and Owen, S. and Soiland-Reyes, S. and Dunlop, I. and Nenadic, A. and Fisher, P. and Bhagat, J. and Belhajjame, K. and Bacall, F. and Hardisty, A. and {Nieva de la Hidalga}, A. and {Balcazar Vargas}, M. P. and Sufi, S. and Goble, C.},
doi = {10.1093/nar/gkt328},
file = {:Users/adrian/Work/project/papers/The Taverna workflow suite - designing and executing workflows of Web Services on the desktop, web or in the cloud.pdf:pdf},
issn = {0305-1048},
journal = {Nucleic Acids Research},
number = {W1},
pages = {W557--W561},
title = {{The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud}},
url = {http://nar.oxfordjournals.org/lookup/doi/10.1093/nar/gkt328},
volume = {41},
year = {2013}
}
@article{Afgan2011,
abstract = {Continuing evolution of DNA sequencing has transformed modern biology. Lower sequencing costs coupled with novel sequencing-based assays have led to rapid adoption of next-generation sequencing across diverse areas of life sciences research14. Sequencing has moved out of the genome centers into core facilities and individual laboratories where any investigator can access it for modest and progressively declining cost. Although easy to generate in tremendous quantities, sequence data are still difficult to manage and analyze. Sophisticated informatics techniques and supporting infrastructure are needed to make sense of even conceptually simple sequencing experiments, let alone the more complex analysis techniques being developed. The most pressing challenge facing the sequencing community today is providing the informatics infrastructure and accessible analysis methods needed to make it possible for all investigators to realize the power of high-throughput sequencing to advance their research},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Afgan, Enis and Baker, Dannon and Coraor, Nate and Goto, Hiroki and Paul, Ian M and Makova, Kateryna D and Nekrutenko, Anton and Taylor, James},
doi = {10.1038/nbt.2028},
eprint = {NIHMS150003},
file = {:Users/adrian/Work/project/papers/Harnessing cloud computing with Galaxy Cloud.pdf:pdf},
isbn = {1087-0156},
issn = {1087-0156},
journal = {Nature Biotechnology},
number = {11},
pages = {972--974},
pmid = {22068528},
title = {{Harnessing cloud computing with Galaxy Cloud}},
volume = {29},
year = {2011}
}
@misc{OpenMOLEEnvironments,
author = {{OpenMOLE Contributors}},
title = {{Open Mole Environments}},
url = {http://www.openmole.org/current/Documentation{\_}Language{\_}Environments.html},
urldate = {2016-01-24}
}
@misc{Taverna,
author = {{Taverna Contributors}},
keywords = {Java,Taverna,e-science,escience,in silico,open source,scientific,workflow management system,workflows},
title = {{Taverna - Open source and domain independent Workflow Management System}},
url = {http://www.taverna.org.uk/},
urldate = {2016-01-24}
}
@misc{Amazon,
author = {Amazon},
title = {{Amazon Elastic Compute Cloud (EC2) Cloud Server {\&} Hosting}},
url = {https://aws.amazon.com/ec2/},
urldate = {2016-01-24}
}
@article{Juve2013,
abstract = {Researchers working on the planning, scheduling, and execution of scientific workflows need access to a wide variety of scientific workflows to evaluate the performance of their implementations. This paper provides a characterization of workflows from six diverse scientific applications, including astronomy, bioinformatics, earthquake science, and gravitational-wave physics. The characterization is based on novel workflow profiling tools that provide detailed information about the various computational tasks that are present in the workflow. This information includes I/O, memory and computational characteristics. Although the workflows are diverse, there is evidence that each workflow has a job type that consumes the most amount of runtime. The study also uncovered inefficiency in a workflow component implementation, where the component was re-reading the same data multiple times. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Juve, Gideon and Chervenak, Ann and Deelman, Ewa and Bharathi, Shishir and Mehta, Gaurang and Vahi, Karan},
doi = {10.1016/j.future.2012.08.015},
file = {:Users/adrian/Work/project/papers/Characterizing and Profiling Scientific Workflows.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Measurement,Performance,Profiling,Scientific workflows},
number = {3},
pages = {682--692},
title = {{Characterizing and profiling scientific workflows}},
url = {http://dx.doi.org/10.1016/j.future.2012.08.015},
volume = {29},
year = {2013}
}
@misc{Reuillon2012,
author = {Reuillon, Romain},
booktitle = {Clasyco},
title = {{OpenMOLE: a DSL to explore complex-system models}},
url = {http://www.openmole.org/files/openmole-com/slides/2012/dsl/},
year = {2012}
}
@misc{TavernaGrid,
author = {caGrid Contributors},
title = {{Taverna caGrid}},
url = {https://github.com/NCIP/taverna-grid},
urldate = {2016-01-24}
}
@article{Taylor2007,
abstract = {Scientific Workflow has seen massive growth in recent years as science becomes increasingly reliant on the analysis of massive data sets and the use of distributed resources. The workflow programming paradigm is seen as a means of managing the complexity in defining the analysis, executing the necessary computations on distributed resources, collecting information about the analysis results, and providing means to record and reproduce the scientific analysis.Workflows for e-Science presents an overview of the current state of the art in the field. It brings together research from many of leading computer scientists in the workflow area and provides real world examples from domain scientists actively involved in e-Science. The computer science topics addressed in the book provide a broad overview of active research focusing on the areas of workflow representations and process models, component and service-based workflows, standardization efforts, workflow frameworks and tools, and problem solving environments and portals. The topics covered represent a broad range of scientific workflow and will be of interest to a wide range of computer science researchers, domain scientists interested in applying workflow technologies in their work, and engineers wanting to develop workflow systems and tools. As such Workflows for e-Science is an invaluable resource for potential or existing users of workflow technologies and a benchmark for developers and researchers.Ian Taylor is Lecturer in Computer Science at Cardiff University, and coordinator of Triana activities at Cardiff. He is the author of "From P2P to Web Services and Grids", also published by Springer. Ewa Deelman is a Research Assistant Professor at the USC Computer Science Department and a Research Team Leader at the Center for Grid Technologies at the USC Information Sciences Institute. Dennis Gannon is a professor of Computer Science in the School of Informatics at Indiana University. He is also Science Director for the Indiana Pervasive Technology Labs..Dr Shields is a research associate at Cardiff and one of two lead developers for the Triana project.},
author = {Taylor, Ian and Deelman, Ewa and Gannon, Dennis and Shields, Matthew S.},
doi = {10.1007/978-1-84628-757-2},
file = {:Users/adrian/Work/project/papers/Workflows for e-Science.pdf:pdf},
isbn = {978-1-84628-519-6},
issn = {1849966192},
journal = {Workflows for e-Science: Scientific Workflows for Grids},
pages = {1--523},
title = {{Workflows for e-Science: Scientific Workflows for Grids}},
url = {http://link.springer.com/10.1007/978-1-84628-757-2},
year = {2007}
}
@misc{PBS,
author = {{Advanced Research Computing}},
title = {{The PBS job scheduler}},
url = {http://www.arc.ox.ac.uk/content/pbs},
urldate = {2016-01-24}
}
