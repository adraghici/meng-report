@article{Wolstencroft2013,
author = {Wolstencroft, K. and Haines, R. and Fellows, D. and Williams, A. and Withers, D. and Owen, S. and Soiland-Reyes, S. and Dunlop, I. and Nenadic, A. and Fisher, P. and Bhagat, J. and Belhajjame, K. and Bacall, F. and Hardisty, A. and {Nieva de la Hidalga}, A. and {Balcazar Vargas}, M. P. and Sufi, S. and Goble, C.},
doi = {10.1093/nar/gkt328},
file = {:Users/adrian/Work/project/papers/The Taverna workflow suite - designing and executing workflows of Web Services on the desktop, web or in the cloud.pdf:pdf},
issn = {0305-1048},
journal = {Nucleic Acids Research},
number = {W1},
pages = {W557--W561},
title = {{The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud}},
url = {http://nar.oxfordjournals.org/lookup/doi/10.1093/nar/gkt328},
volume = {41},
year = {2013}
}
@article{Wu2015,
author = {Wu, Fuhui and Wu, Qingbo and Tan, Yusong},
doi = {10.1007/s11227-015-1438-4},
file = {:Users/adrian/Work/project/papers/Workflow scheduling in cloud - a survey.pdf:pdf},
isbn = {978-1-4799-5467-4},
issn = {1573-0484},
journal = {The Journal of Supercomputing},
keywords = {Cloud computing,Data-intensive workflow scheduling,Hybrid environment,QoS constrained scheduling,Robust scheduling,Workflow scheduling,Workflow-as-a-service,cloud computing,data-intensive,hybrid environment,qos constrained scheduling,robust scheduling,workflow scheduling,workflow-as-a-service},
month = {may},
number = {9},
pages = {3373--3418},
title = {{Workflow scheduling in cloud : a survey}},
url = {"http://dx.doi.org/10.1007/s11227-015-1438-4},
volume = {71},
year = {2015}
}
@article{Reuillon2016,
author = {Passerat-Palmbach, Jonathan and Rueckert, Daniel and Reuillon, Romain},
file = {:Users/adrian/Work/project/papers/GridScale - distributed computing for applications running in the Java Virtual Machine.pdf:pdf},
title = {{GridScale: distributed computing for applications running in the Java Virtual Machine}},
year = {2016}
}
@article{Reuillon2013,
abstract = {Complex-systems describe multiple levels of collective structure and organization. In such systems, the emergence of global behaviour from local interactions is generally studied through large scale experiments on numerical models. This analysis generates important computation loads which require the use of multi-core servers, clusters or grid computing. Dealing with such large scale executions is especially challenging for modellers who do not possess the theoretical and methodological skills required to take advantage of high performance computing environments. That is why we have designed a cloud approach for model experimentation. This approach has been implemented in OpenMOLE (Open MOdeL Experiment) as a Domain Specific Language (DSL) that leverages the naturally parallel aspect of model experiments. The OpenMOLE DSL has been designed to explore user-supplied models. It delegates transparently their numerous executions to remote execution environment. From a user perspective, those environments are viewed as services providing computing power, therefore no technical detail is ever exposed. This paper presents the OpenMOLE DSL through the example of a toy model exploration and through the automated calibration of a real-world complex-system model in the field of geography. ?? 2013 Elsevier B.V. All rights reserved.},
author = {Reuillon, Romain and Leclaire, Mathieu and Rey-Coyrehourcq, Sebastien},
doi = {10.1016/j.future.2013.05.003},
file = {:Users/adrian/Work/project/papers/OpenMOLE, a workflow engine specifically tailored for the distributed exploration of simulation models.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud computing,Complex-systems,Distributed computing,Model exploration,Workflow},
number = {8},
pages = {1981--1990},
title = {{OpenMOLE, a workflow engine specifically tailored for the distributed exploration of simulation models}},
volume = {29},
year = {2013}
}
@article{Afgan2011,
abstract = {Continuing evolution of DNA sequencing has transformed modern biology. Lower sequencing costs coupled with novel sequencing-based assays have led to rapid adoption of next-generation sequencing across diverse areas of life sciences research14. Sequencing has moved out of the genome centers into core facilities and individual laboratories where any investigator can access it for modest and progressively declining cost. Although easy to generate in tremendous quantities, sequence data are still difficult to manage and analyze. Sophisticated informatics techniques and supporting infrastructure are needed to make sense of even conceptually simple sequencing experiments, let alone the more complex analysis techniques being developed. The most pressing challenge facing the sequencing community today is providing the informatics infrastructure and accessible analysis methods needed to make it possible for all investigators to realize the power of high-throughput sequencing to advance their research},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Afgan, Enis and Baker, Dannon and Coraor, Nate and Goto, Hiroki and Paul, Ian M and Makova, Kateryna D and Nekrutenko, Anton and Taylor, James},
doi = {10.1038/nbt.2028},
eprint = {NIHMS150003},
file = {:Users/adrian/Work/project/papers/Harnessing cloud computing with Galaxy Cloud.pdf:pdf},
isbn = {1087-0156},
issn = {1087-0156},
journal = {Nature Biotechnology},
number = {11},
pages = {972--974},
pmid = {22068528},
title = {{Harnessing cloud computing with Galaxy Cloud}},
volume = {29},
year = {2011}
}
@article{Curcin2008,
abstract = {The past decade has witnessed a growing trend in designing and using workflow systems with a focus on supporting the scientific research process in bioinformatics and other areas of life sciences. The aim of these systems is mainly to simplify access, control and orchestration of remote distributed scientific data sets using remote computational resources, such as EBI web services. In this paper we present the state of the art in the field by reviewing six such systems: Discovery Net, Taverna, Triana, Kepler, Yawl and BPEL. We provide a high-level framework for comparing the systems based on their control flow and data flow properties with a view of both informing future research in the area by academic researchers and facilitating the selection of the most appropriate system for a specific application task by practitioners.},
author = {Curcin, V. and Ghanem, M.},
doi = {10.1109/CIBEC.2008.4786077},
file = {:Users/adrian/Library/Application Support/Mendeley Desktop/Downloaded/Curcin, Ghanem - 2008 - Scientific workflow systems - can one size fit all.pdf:pdf},
isbn = {978-1-4244-2694-2},
issn = {1424426944},
journal = {2008 Cairo International Biomedical Engineering Conference},
keywords = {Bioinformatics,Business,Control systems,Data analysis,Data mining,Distributed computing,EBI Web services,Educational institutions,Grid computing,Testing,Web services,bioinformatics,control flow,data flow,distributed databases,remote computational resources,remote distributed scientific data sets,scientific workflow systems,workflow systems},
pages = {1--9},
title = {{Scientific workflow systems - can one size fit all?}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4786077},
year = {2008}
}
@article{Schmitt2015,
abstract = {Multi-agent geographical models integrate very large numbers of spatial interactions. In order to validate those models large amount of computing is necessary for their simulation and calibration. Here a new data processing chain including an automated calibration procedure is experimented on a computational grid using evolutionary algorithms. This is applied for the first time to a geographical model designed to simulate the evolution of an early urban settlement system. The method enables us to reduce the computing time and provides robust results. Using this method, we identify several parameter settings that minimise three objective functions that quantify how closely the model results match a reference pattern. As the values of each parameter in different settings are very close, this estimation considerably reduces the initial possible domain of variation of the parameters. The model is thus a useful tool for further multiple applications on empirical historical situations.},
author = {Schmitt, Clara and Rey-Coyrehourcq, S{\'{e}}bastien and Reuillon, Romain and Pumain, Denise},
doi = {10.1068/b130064p},
file = {:Users/adrian/Library/Application Support/Mendeley Desktop/Downloaded/Schmitt et al. - 2015 - Half a billion simulations evolutionary algorithms and distributed computing for calibrating the SimpopLocal geo.pdf:pdf},
issn = {0265-8135, 1472-3417},
journal = {Environment and Planning B: Planning and Design},
keywords = {calibration,evolutionary algorithm,geographical,high performance computing,model validation,modelling,multi-agent system,simulation model},
number = {0},
pages = {0--0},
title = {{Half a billion simulations: evolutionary algorithms and distributed computing for calibrating the SimpopLocal geographical model}},
url = {http://www.arxiv.org/pdf/1502.06752.pdf},
volume = {0},
year = {2015}
}
@article{Deelman2004,
abstract = {In this paper we describe the Pegasus system that can map complex workflows onto the Grid. Pegasus takes an abstract description of a workflow and finds the appropriate data and Grid resources to execute the workflow. Pegasus is being released as part of the GriPhyN Virtual Data Toolkit and has been used in a variety of applications ranging from astronomy, biology, gravitational-wave science, and high-energy physics. A deferred planning mode of Pegasus is also introduced.},
author = {Deelman, Ewa and Blythe, James and Gil, Yolanda and Kesselman, Carl},
doi = {10.1007/978-3-540-28642-4_2},
file = {:Users/adrian/Work/project/papers/Pegasus - Mapping Scientific Workflows onto the Grid.pdf:pdf},
isbn = {978-3-540-22888-2},
issn = {1541-1672},
journal = {Grid Computing},
pages = {131--140},
pmid = {8425240},
title = {{Pegasus: Mapping scientific workflows onto the grid}},
url = {http://www.springerlink.com/index/95rj5e2fgqqpkaha.pdf},
volume = {3165/2004},
year = {2004}
}
@article{Deelman2013,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and protein−protein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD ≤ 2.0 {\AA} for the interface backbone atoms) increased from 21{\%} with default Glide SP settings to 58{\%} with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63{\%} success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40{\%} of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Deelman, Ewa},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/adrian/Work/project/papers/Pegasus, a Workflow Management System for Science Automation.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Journal of Chemical Information and Modeling},
keywords = {pegasus,scientific workflow,workflow management system},
pages = {160},
pmid = {25246403},
title = {{Pegasus, a Workflow Management System for Large-Scale Science}},
year = {2013}
}
@article{Juve2013,
abstract = {Researchers working on the planning, scheduling, and execution of scientific workflows need access to a wide variety of scientific workflows to evaluate the performance of their implementations. This paper provides a characterization of workflows from six diverse scientific applications, including astronomy, bioinformatics, earthquake science, and gravitational-wave physics. The characterization is based on novel workflow profiling tools that provide detailed information about the various computational tasks that are present in the workflow. This information includes I/O, memory and computational characteristics. Although the workflows are diverse, there is evidence that each workflow has a job type that consumes the most amount of runtime. The study also uncovered inefficiency in a workflow component implementation, where the component was re-reading the same data multiple times. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Juve, Gideon and Chervenak, Ann and Deelman, Ewa and Bharathi, Shishir and Mehta, Gaurang and Vahi, Karan},
doi = {10.1016/j.future.2012.08.015},
file = {:Users/adrian/Work/project/papers/Characterizing and Profiling Scientific Workflows.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Measurement,Performance,Profiling,Scientific workflows},
number = {3},
pages = {682--692},
title = {{Characterizing and profiling scientific workflows}},
url = {http://dx.doi.org/10.1016/j.future.2012.08.015},
volume = {29},
year = {2013}
}
@article{Goble2009,
abstract = {Increasingly, scientific breakthroughs will be powered by advanced computing capabilities that help researchers manipulate and explore massive datasets.  The speed at which any given scientific discipline advances will depend on how well its researchers collaborate with one another, and with technologists, in areas of eScience such as databases, workflow management, visualization, and cloud computing technologies.  In The Fourth Paradigm: Data-Intensive Scientific Discovery, the collection of essays expands on the vision of pioneering computer scientist Jim Gray for a new, fourth paradigm of discovery based on data-intensive science and offers insights into how it can be fully realized.},
author = {Goble, Carole and {De Roure}, David},
file = {:Users/adrian/Work/project/papers/The Impact of Workflow Tools on Data-centric Research.pdf:pdf},
isbn = {978-0-9825442-0-4},
journal = {The Fourth Paradigm: Data-Intensive Scientific Discovery},
keywords = {computability,computational methods,computational science,data intensity,data mining,eScience,ensemble,information theory,knowledge acquisition,knowledge-base,modeling,pattern recognition,scientific discovery},
pages = {137--145},
title = {{The Impact of Workflow Tools on Data-centric Research}},
url = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/default.aspx},
year = {2009}
}
@article{Reuillon2010,
abstract = {In this paper we present {\{}OpenMOLE{\}}, a scientific framework providing a virtualized runtime environment for distributed computing. Current distributed execution systems do not hide the hardware and software heterogeneity of computing and data resources whereas {\{}OpenMOLE{\}} provides generic services to develop distributed scientific algorithms independently from the execution environment architecture. {\{}OpenMOLE{\}} uses abstraction layers to delegate computing tasks with the same high level interface for the major underlying architectures: local processors, batch systems, computational grids, Internet computing and cloud computing. The file access abstraction layer is another key feature helping a generic usage of the computation power provided by grids and clusters. The {\{}OpenMOLE{\}} framework has been tested with the exploration of a bacterial biofilm simulation with an individual-based model.},
author = {Reuillon, Romain and Chuffart, Florent and Leclaire, Mathieu and Faure, Thierry and Dumoulin, Nicolas and Hill, David},
doi = {10.1109/HPCS.2010.5547155},
file = {:Users/adrian/Work/project/papers/Declarative tak delegation in OpenMOLE.pdf:pdf},
isbn = {9781424468300},
journal = {High Performance Computing and Simulation (HPCS), 2010 International Conference on},
keywords = {2,design of computer experiments,distributed simulation,ex-,exploration,grid computing,high perfomance computing,related work in distributed,task delegation},
pages = {55--62},
title = {{Declarative task delegation in OpenMOLE}},
year = {2010}
}
@misc{Kepler,
title = {{The Kepler Project}},
url = {https://kepler-project.org/},
urldate = {2016-01-24}
}
@misc{Taverna,
keywords = {Java,Taverna,e-science,escience,in silico,open source,scientific,workflow management system,workflows},
title = {{Taverna - Open source and domain independent Workflow Management System}},
url = {http://www.taverna.org.uk/},
urldate = {2016-01-24}
}
@misc{Pegasus,
title = {{Pegasus}},
url = {http://pegasus.isi.edu/},
urldate = {2016-01-24}
}
@article{Reuillon2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.04182v1},
author = {Reuillon, Romain and Passerat-Palmbach, Jonathan},
doi = {10.1109/HPCSim.2015.7237015},
eprint = {arXiv:1506.04182v1},
file = {:Users/adrian/Work/project/papers/Model Exploration Using OpenMOLE - a workflow engine for large scale distributed design of experiments and parameter tuning.pdf:pdf},
isbn = {9781467378123},
journal = {IEEE High Performance Computing and Simulation conference 2015.},
title = {{Model Exploration Using OpenMOLE a workflow engine for large scale distributed design of experiments and parameter tuning}},
year = {2015}
}
@article{Koteska,
author = {Koteska, Bojana and Jakimovski, Boro and Mishev, Anastas},
file = {:Users/adrian/Work/project/papers/Building Scientific Workflows on the Grid - A Comparison between OpenMole and Taverna.pdf:pdf},
keywords = {-scientific workflow,4,are structured based on,control and data dependencies,grid,java,openmole,scientific process where tasks,taverna,the goal of scientific,the main purpose of,the scientific workflow is,their,to automate the},
title = {{Building Scientific Workflows on the Grid : A Comparison between OpenMole and Taverna}}
}
@article{Afgan2010,
abstract = {Widespread adoption of high-throughput sequencing has greatly increased the scale and sophistication of computational infrastructure needed to perform genomic research. An alternative to building and maintaining local infrastructure is "cloud computing", which, in principle, offers on demand access to flexible computational infrastructure. However, cloud computing resources are not yet suitable for immediate "as is" use by experimental biologists.},
author = {Afgan, Enis and Baker, Dannon and Coraor, Nate and Chapman, Brad and Nekrutenko, Anton and Taylor, James},
doi = {10.1186/1471-2105-11-S12-S4},
file = {:Users/adrian/Work/project/papers/Galaxy CloudMan - delivering cloud compute clusters.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$n1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
number = {Suppl 12},
pages = {S4},
pmid = {21210983},
title = {{Galaxy CloudMan: delivering cloud compute clusters}},
url = {http://www.biomedcentral.com/1471-2105/11/S12/S4},
volume = {11 Suppl 1},
year = {2010}
}
@article{Taylor2007,
abstract = {Scientific Workflow has seen massive growth in recent years as science becomes increasingly reliant on the analysis of massive data sets and the use of distributed resources. The workflow programming paradigm is seen as a means of managing the complexity in defining the analysis, executing the necessary computations on distributed resources, collecting information about the analysis results, and providing means to record and reproduce the scientific analysis.Workflows for e-Science presents an overview of the current state of the art in the field. It brings together research from many of leading computer scientists in the workflow area and provides real world examples from domain scientists actively involved in e-Science. The computer science topics addressed in the book provide a broad overview of active research focusing on the areas of workflow representations and process models, component and service-based workflows, standardization efforts, workflow frameworks and tools, and problem solving environments and portals. The topics covered represent a broad range of scientific workflow and will be of interest to a wide range of computer science researchers, domain scientists interested in applying workflow technologies in their work, and engineers wanting to develop workflow systems and tools. As such Workflows for e-Science is an invaluable resource for potential or existing users of workflow technologies and a benchmark for developers and researchers.Ian Taylor is Lecturer in Computer Science at Cardiff University, and coordinator of Triana activities at Cardiff. He is the author of "From P2P to Web Services and Grids", also published by Springer. Ewa Deelman is a Research Assistant Professor at the USC Computer Science Department and a Research Team Leader at the Center for Grid Technologies at the USC Information Sciences Institute. Dennis Gannon is a professor of Computer Science in the School of Informatics at Indiana University. He is also Science Director for the Indiana Pervasive Technology Labs..Dr Shields is a research associate at Cardiff and one of two lead developers for the Triana project.},
author = {Taylor, Ian and Deelman, Ewa and Gannon, Dennis and Shields, Matthew S.},
doi = {10.1007/978-1-84628-757-2},
file = {:Users/adrian/Work/project/papers/Workflows for e-Science.pdf:pdf},
isbn = {978-1-84628-519-6},
issn = {1849966192},
journal = {Workflows for e-Science: Scientific Workflows for Grids},
pages = {1--523},
title = {{Workflows for e-Science: Scientific Workflows for Grids}},
url = {http://link.springer.com/10.1007/978-1-84628-757-2},
year = {2007}
}
@misc{StarCluster,
title = {{STAR: Cluster}},
url = {http://star.mit.edu/cluster/},
urldate = {2016-01-22}
}
@misc{Galaxy,
title = {{The Galaxy Project: Online bioinformatics analysis for everyone}},
url = {https://galaxyproject.org/},
urldate = {2016-01-24}
}
@misc{OpenMOLE,
keywords = {Cluster,Data Parallelism,Design of Experiment,Distributed Computing,Grid,Model Exploration,Parameter Tuning,Scientific Workflow Engine,Sensitivity Analysis},
title = {{OpenMOLE}},
url = {http://www.openmole.org/},
urldate = {2016-01-24}
}
@misc{Yapa,
title = {{Yapa}},
url = {https://github.com/openmole/yapa},
urldate = {2016-01-24}
}
@misc{EGI,
title = {{EGI - European Grid Infrastructure}},
url = {http://www.egi.eu/},
urldate = {2016-01-24}
}
@misc{OpenMOLEDSL,
title = {{Open Mole Environments}},
url = {http://www.openmole.org/current/Documentation$\backslash${\_}Language$\backslash${\_}Environments.html},
urldate = {2016-01-24}
}
@misc{OpenMOLEMarketplace,
title = {{OpenMOLE Marketplace}},
url = {https://github.com/openmole/openmole-market},
urldate = {2016-01-24}
}
@misc{PBS,
title = {{The PBS job scheduler}},
url = {http://www.arc.ox.ac.uk/content/pbs},
urldate = {2016-01-24}
}
@misc{Torque,
keywords = {Adaptive Computing},
title = {{TORQUE Resource Manager}},
url = {http://www.adaptivecomputing.com/products/open-source/torque/},
urldate = {2016-01-24}
}
@misc{SGE,
annote = {Previously known as Sun Grid Engine or Oracle Grid Engine.},
title = {{Open Grid Engine}},
url = {http://sourceforge.net/projects/gridscheduler/},
urldate = {2016-01-24}
}
@misc{SLURM,
keywords = {Linux clusters,SLURM,Simple Linux Utility for Resource Management,high-performance computing,resource management},
title = {{Simple Linux Utility for Resource Management}},
url = {http://slurm.schedmd.com/},
urldate = {2016-01-24}
}
@misc{HTCondor,
title = {{HTCondor}},
url = {https://research.cs.wisc.edu/htcondor/},
urldate = {2016-01-24}
}
@misc{OAR,
keywords = {start},
title = {{OAR}},
url = {https://oar.imag.fr/},
urldate = {2016-01-24}
}
@misc{Reuillon2012,
author = {Reuillon, Romain},
booktitle = {Clasyco},
title = {{OpenMOLE: a DSL to explore complex-system models}},
url = {http://www.openmole.org/files/openmole-com/slides/2012/dsl/},
year = {2012}
}
@article{Goecks2010,
abstract = {Increased reliance on computational approaches in the life sciences has revealed grave concerns about how accessible and reproducible computation-reliant results truly are. Galaxy http://usegalaxy.org, an open web-based platform for genomic research, addresses these problems. Galaxy automatically tracks and manages data provenance and provides support for capturing the context and intent of computational methods. Galaxy Pages are interactive, web-based documents that provide users with a medium to communicate a complete computational analysis.},
author = {Goecks, Jeremy and Nekrutenko, Anton and Taylor, James},
doi = {10.1186/gb-2010-11-8-r86},
file = {:Users/adrian/Work/project/papers/Galaxy - a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences.pdf:pdf},
isbn = {1465-6914 (Electronic)$\backslash$r1465-6906 (Linking)},
issn = {1465-6906},
journal = {Genome biology},
number = {8},
pages = {R86},
pmid = {20738864},
title = {{Galaxy: a comprehensive approach for supporting accessible, reproducible, and transparent computational research in the life sciences.}},
volume = {11},
year = {2010}
}
@misc{EC2,
title = {{Amazon Elastic Compute Cloud (EC2) Cloud Server {\&} Hosting}},
url = {https://aws.amazon.com/ec2/},
urldate = {2016-01-24}
}
@misc{caGrid,
title = {{caGrid}},
url = {http://www.cagrid.org/display/cagridhome/Home},
urldate = {2016-01-24}
}
@article{Abouelhoda2012,
abstract = {ABSTRACT: BACKGROUND: Over the past decade the workflow system paradigm has evolved as an efficient and user-friendly approach for developing complex bioinformatics applications. Two popular workflow systems that have gained acceptance by the bioinformatics community are Taverna and Galaxy. Each system has a large user-base and supports an ever-growing repository of application workflows. However, workflows developed for one system cannot be imported and executed easily on the other. The lack of interoperability is due to differences in the models of computation, workflow languages, and system architectures of both systems. This lack of interoperability limits sharing of workflows between the user communities and leads to duplication of development efforts. RESULTS: In this paper, we present Tavaxy, a stand-alone system for creating and executing workflows based on using an extensible set of re-usable workflow patterns. Tavaxy offers a set of new features that simplify and enhance the development of sequence analysis applications: It also allows the integration of existing Taverna and Galaxy workflows in a single environment, and supports the use of cloud computing capabilities. The integration of existing Taverna and Galaxy workflows is supported seamlessly at both run-time and design-time levels, based on the concepts of hierarchical workflows and workflow patterns. The use of cloud computing in Tavaxy is flexible, where the users can either instantiate the whole system on the cloud, or delegate the execution of certain sub-workflows to the cloud infrastructure. CONCLUSIONS: Tavaxy reduces the workflow development cycle by introducing the use of workflow patterns to simplify workflow creation. It enables the re-use and integration of existing (sub-) workflows from Taverna and Galaxy, and allows the creation of hybrid workflows. Its additional features exploit recent advances in high performance cloud computing to cope with the increasing data size and complexity of analysis. The system can be accessed either through a cloud-enabled web-interface or downloaded and installed to run within the user's local environment. All resources related to Tavaxy are available at http://www.tavaxy.org.},
author = {Abouelhoda, Mohamed and Issa, Shadi a and Ghanem, Moustafa},
doi = {10.1186/1471-2105-13-77},
file = {:Users/adrian/Work/project/papers/Tavaxy - Integrating Taverna and Galaxy workflows with cloud computing support.pdf:pdf},
isbn = {1471-2105 (Electronic)$\backslash$n1471-2105 (Linking)},
issn = {1471-2105},
journal = {BMC bioinformatics},
number = {1},
pages = {77},
pmid = {22559942},
title = {{Tavaxy: Integrating Taverna and Galaxy workflows with cloud computing support.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22559942},
volume = {13},
year = {2012}
}
@misc{Donvito,
author = {Donvito, Giacinto},
title = {{BioVeL: Taverna Workflows on distributed grid computing for Biodiversity}},
url = {https://indico.egi.eu/indico/event/1222/session/34/contribution/53/material/slides/0.pdf},
urldate = {2016-01-24}
}
@misc{TavernaGrid,
title = {{Taverna caGrid}},
url = {https://github.com/NCIP/taverna-grid},
urldate = {2016-01-24}
}
@misc{BioVeL,
title = {{BioVeL}},
url = {https://www.biovel.eu/},
urldate = {2016-01-24}
}
@misc{EBS,
title = {{Amazon Elastic Block Store (EBS) – AWS Block Storage}},
url = {https://aws.amazon.com/ebs/},
urldate = {2016-01-25}
}
@misc{S3,
title = {{Amazon Simple Storage Service (S3) - Object Storage}},
url = {https://aws.amazon.com/s3/},
urldate = {2016-01-25}
}
@misc{PegasusTutorial,
title = {{Running Workflows on Amazon EC2 using Pegasus}},
url = {https://confluence.pegasus.isi.edu/display/pegasus/Cloud+Tutorial},
urldate = {2016-01-26}
}
@article{Korambath2014,
abstract = {21st Century Smart Manufacturing (SM) is manufacturing in which all information is available when it is needed, where it is needed, and in the form it is most useful [1,2] to drive optimal actions and responses. The 21st Century SM enterprise is data driven, knowledge enabled, and model rich with visibility across the enterprise (internal and external) such that all operating actions are determined and executed proactively by applying the best information and a wide range of performance metrics. SM also encompasses the sophisticated practice of generating and applying data-driven Manufacturing Intelligence throughout the lifecycle of design, engineering, planning and production. Workflow is foundational in orchestrating dynamic, adaptive, actionable decision-making through the contextualization and understanding of data. Pervasive deployment of architecturally consistent workflow applications creates the enterprise environment for manufacturing intelligence. Workflow as a Service (WfaaS) software allows task orchestration and facilitates workflow services and manage environment to integrate interrelated task components. Apps, and toolkits are required to assemble customized SM applications on a common, standards based workflow architecture and deploy on infrastructure that is accessible by small, medium, and large companies. Incorporating dynamic decision-making steps through contextualization of real-time data requires scientific workflow software such as Kepler. By combining workflow, private cloud computing and web services technologies, we built a prototype test bed to test a furnace temperature control model. {\textcopyright} The Authors. Published by Elsevier B.V.},
author = {Korambath, Prakashan and Wang, Jianwu and Kumar, Ankur and Hochstein, Lorin and Schott, Brian and Graybill, Robert and Baldea, Michael and Davis, Jim},
doi = {10.1016/j.procs.2014.05.210},
file = {:Users/adrian/Work/project/papers/Deploying Kepler Workflows as Services on a Cloud Infrastructure for Smart Manufacturing.pdf:pdf},
isbn = {1877-0509},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Cloud computing,Kepler workflows,Smart manufacturing,Workflow as a service},
pages = {2254--2259},
publisher = {Elsevier Masson SAS},
title = {{Deploying kepler workflows as services on a cloud infrastructure for smart manufacturing}},
url = {http://dx.doi.org/10.1016/j.procs.2014.05.210},
volume = {29},
year = {2014}
}
@article{Ludascher2006,
author = {Lud{\"{a}}scher, Bertram and Altintas, Ilkay and Berkley, Chad and Higgins, Dan and Jaeger, Efrat and Jones, Matthew and Lee, Edward A. and Tao, Jing and Zhao, Yang},
doi = {10.1002/cpe.994},
file = {:Users/adrian/Work/project/papers/Scientific workflow management and the Kepler system.pdf:pdf},
issn = {1532-0626},
journal = {Concurrency and Computation: Practice and Experience},
keywords = {bertram lud,correspondence to,dataflow networks,grid workflows,ments,problem-solving environ-,scientific data management,scientific workflows},
number = {10},
pages = {1039--1065},
title = {{Scientific workflow management and the Kepler system}},
url = {http://doi.wiley.com/10.1002/cpe.994},
volume = {18},
year = {2006}
}
@article{Deelman2010,
abstract = {Scientific workflows are frequently being used to model complex phenomena, to analyze instrumental data, to tie together information from distributed sources, and to pur- sue other scientific endeavors. Out of necessity, these complex applications need to execute in distributed envi- ronments and make use of a number of heterogeneous resources. In this paper we describe some of these appli- cations and illustrate techniques that improve their per- formance and reliably in distributed environments, such as grids and clouds. Although clouds were first introduced in the business arena, they have a potential to be provide on- demand resources for scientific computations.},
author = {Deelman, E.},
doi = {10.1177/1094342009356432},
file = {:Users/adrian/Work/project/papers/Grids and Clouds - Making Workflow Applications Work in Heterogeneous Distributed Environments.pdf:pdf},
isbn = {1094342009356},
issn = {1094-3420},
journal = {International Journal of High Performance Computing Applications},
keywords = {applications,cloud com-,grid computing,heterogeneous distributed environ-,puting,scientific workflows},
number = {3},
pages = {284--298},
title = {{Grids and Clouds: Making Workflow Applications Work in Heterogeneous Distributed Environments}},
volume = {24},
year = {2010}
}
@article{Wang2012,
author = {Wang, Jianwu and Altintas, Ilkay},
doi = {10.1016/j.procs.2012.04.179},
file = {:Users/adrian/Work/project/papers/Early Cloud Experiences with the Kepler Scientific Workflow System.pdf:pdf},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {amazon ec2,bioinformatics,cloud computing,data-intensive,scientific workflows},
pages = {1630--1634},
title = {{Early Cloud Experiences with the Kepler Scientific Workflow System}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1877050912003006},
volume = {9},
year = {2012}
}
@article{Juve2009,
abstract = {The proliferation of commercial cloud computing providers has generated significant interest in the scientific computing community. Much recent research has attempted to determine the benefits and drawbacks of cloud computing for scientific applications. Although clouds have many attractive features, such as virtualization, on-demand provisioning, and {\^{A}}¿pay as you go{\^{A}}¿ usage-based pricing, it is not clear whether they are able to deliver the performance required for scientific applications at a reasonable price. In this paper we examine the performance and cost of clouds from the perspective of scientific workflow applications. We use three characteristic workflows to compare the performance of a commercial cloud with that of a typical HPC system, and we analyze the various costs associated with running those workflows in the cloud. We find that the performance of clouds is not unreasonable given the hardware resources provided, and that performance comparable to HPC systems can be achieved given similar resources. We also find that the cost of running workflows on a commercial cloud can be reduced by storing data in the cloud rather than transferring it from outside.},
archivePrefix = {arXiv},
arxivId = {1005.2718},
author = {Juve, Gideon and Deelman, Ewa and Vahi, Karan and Mehta, Gaurang and Berriman, Bruce and Berman, Benjamin P. and Maechling, Phil},
doi = {10.1109/ESCIW.2009.5408002},
eprint = {1005.2718},
file = {:Users/adrian/Work/project/papers/Scientific Workflow Applications on Amazon EC2.pdf:pdf},
isbn = {978-1-4244-5946-9},
journal = {2009 5th IEEE International Conference on E-Science Workshops},
keywords = {[Electronic Manuscript]},
pages = {59--66},
title = {{Scientific workflow applications on Amazon EC2}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5408002},
year = {2009}
}
@misc{Scala,
title = {{The Scala Programming Language}},
url = {http://scala-lang.org/},
urldate = {2016-01-29}
}
@misc{CloudStack,
title = {{Apache CloudStack: Open Source Cloud Computing}},
url = {https://cloudstack.apache.org/},
urldate = {2016-01-29}
}
@misc{GoogleCloud,
title = {{Google Cloud Platform}},
url = {https://cloud.google.com/},
urldate = {2016-01-29}
}
@misc{OpenStack,
title = {{OpenStack Open Source Cloud Computing Software}},
url = {https://www.openstack.org/},
urldate = {2016-01-29}
}
@misc{Supercomp,
title = {{TOP500 Supercomputer Sites}},
url = {http://www.top500.org/featured/top-systems/},
urldate = {2016-01-29}
}
@misc{EMI,
title = {{European Middleware Initiative}},
url = {http://www.eu-emi.eu/},
urldate = {2016-01-29}
}
@misc{Myerson,
author = {Myerson, Judith M.},
keywords = {TTA00},
language = {en},
month = {mar},
title = {{Cloud computing versus grid computing}},
url = {http://www.ibm.com/developerworks/library/wa-cloudgrid/},
urldate = {2016-01-29}
}
@misc{CloudsGrids,
title = {{Clouds and grids compared - Cloud lounge}},
url = {http://www.cloud-lounge.org/clouds-and-grids-compared.html},
urldate = {2016-01-29}
}
@misc{AWS,
title = {{Amazon Web Services}},
url = {https://aws.amazon.com/},
urldate = {2016-01-29}
}
@article{Deelman2016,
author = {Deelman, Ewa and Vahi, Karan and Rynge, Mats and Juve, Gideon and Mayani, Rajiv and da Silva, Rafael Ferreira},
doi = {10.1109/MIC.2016.15},
file = {:Users/adrian/Work/project/papers/Pegasus in the Cloud - Science Automation through Workflow Technologies.pdf:pdf},
issn = {1089-7801},
journal = {IEEE Internet Computing},
keywords = {Cloud computing,Distributed processing,Internet,Internet/Web technologies,Power grids,Scientific computing,Web services,cloud computing,distributed computing,grid computing,parallel computing,scientific computing,scientific reproducibility},
number = {1},
pages = {70--76},
title = {{Pegasus in the Cloud: Science Automation through Workflow Technologies}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=7373501},
volume = {20},
year = {2016}
}
@article{Janin2014,
author = {Janin, Yves and Vincent, C{\'{e}}dric and Duraffort, R{\'{e}}mi},
doi = {10.1145/2618137.2618138},
file = {:Users/adrian/Work/project/papers/CARE, the Comprehensive Archiver for Reproducible Execution.pdf:pdf},
isbn = {9781450329514},
journal = {Proceedings of the 1st ACM SIGPLAN Workshop on Reproducible Research Methodologies and New Publication Models in Computer Engineering - TRUST '14},
keywords = {care,computational reproducibility,linux,system calls},
pages = {1--7},
title = {{CARE, the comprehensive archiver for reproducible execution}},
url = {http://dl.acm.org/citation.cfm?doid=2618137.2618138},
year = {2014}
}
@misc{DAGMan,
title = {{DAGMan}},
url = {https://research.cs.wisc.edu/htcondor/dagman/dagman.html},
urldate = {2016-01-24}
}
@article{Singh2008,
abstract = {Many scientific workflows are composed of fine computational granularity tasks, yet they are composed of thousands of them and are data intensive in nature, thus requiring resources such as the TeraGrid to execute efficiently. In order to improve the performance of such applications, we often employ task clustering techniques to increase the computational granularity of workflow tasks. The goal is to minimize the completion time of the workflow by reducing the impact of queue wait times. In this paper, we examine the performance impact of the clustering techniques using the Pegasus workflow management system. Experiments performed using an astronomy workflow on the NCSA TeraGrid cluster show that clustering can achieve a significant reduction in the workflow completion time (up to 97{\%}).},
author = {Singh, Gurmeet and Su, Mei-Hui and Vahi, Karan and Deelman, Ewa and Berriman, Bruce and Good, John and Katz, Daniel and Mehta, Gaurang},
doi = {10.1145/1341811.1341822},
file = {:Users/adrian/Work/project/papers/Workflow Task Clustering for Best Effort Systems with Pegasus.pdf:pdf},
isbn = {9781595938350},
journal = {Mardis Gras Conference},
keywords = {best effort systems,queue,task clustering,workflow clustering},
number = {c},
pages = {8},
title = {{Workflow task clustering for best effort systems with Pegasus}},
url = {http://portal.acm.org/citation.cfm?doid=1341811.1341822},
year = {2008}
}
@misc{jclouds,
title = {{Apache Jclouds}},
url = {https://jclouds.apache.org/},
urldate = {2016-01-29}
}
@misc{OpenMPI,
keywords = {MPI,Open MPI,Open-MPI,OpenMPI,beowulf,cluster,distributed,linux,parallel,parallel computing},
title = {{Open Source High Performance Computing}},
url = {https://www.open-mpi.org/},
urldate = {2016-01-29}
}
@article{NFS,
title = {{NFS: Network File System Protocol specification}},
url = {https://tools.ietf.org/html/rfc1094}
}
@misc{EC2Spot,
title = {{Amazon EC2 Spot Instances}},
url = {https://aws.amazon.com/ec2/spot/},
urldate = {2016-01-29}
}
@misc{Elasticluster,
title = {{Elasticluster}},
url = {https://gc3-uzh-ch.github.io/elasticluster/},
urldate = {2016-01-29}
}
@misc{GlusterFS,
title = {{Storage for your Cloud. — Gluster}},
url = {https://www.gluster.org/},
urldate = {2016-01-29}
}
@misc{Ceph,
title = {{Ceph}},
url = {http://ceph.com/},
urldate = {2016-01-29}
}
@misc{OrangeFS,
title = {{Orange File System}},
url = {http://orangefs.org/},
urldate = {2016-01-29}
}
@misc{Ganglia,
keywords = {Grids,cloud computing,cluster,ganglia,gexec,gmetad,gmond,hadoop,hpc,monitoring,mpi,rrdtool,scientific computing,time-series database},
title = {{Ganglia Monitoring System}},
url = {http://ganglia.info/},
urldate = {2016-01-29}
}
@misc{Ansible,
title = {{Ansible}},
url = {http://www.ansible.com/},
urldate = {2016-01-29}
}
@misc{CloudWatch,
title = {{Amazon CloudWatch}},
url = {https://aws.amazon.com/cloudwatch}
}
@misc{CfnCluster,
title = {{Amazon CfnCluster}},
url = {https://aws.amazon.com/hpc/cfncluster/}
}
@misc{CfnProcesses,
title = {{CfnCluster Processes}},
url = {https://cfncluster.readthedocs.io/en/latest/processes.html}
}
@misc{EMR,
title = {{Amazon Elastic MapReduce}},
url = {https://aws.amazon.com/elasticmapreduce/}
}
@misc{AutoScaling,
title = {{Amazon Auto Scaling}},
url = {https://aws.amazon.com/autoscaling/}
}
@misc{DCOSReq,
title = {{DC/OS System Requirements}},
url = {https://dcos.io/docs/1.7/administration/installing/custom/system-requirements/}
}
@misc{SNS,
title = {{Amazon SNS}},
url = {https://aws.amazon.com/sns/}
}
@misc{AWSPricing,
title = {{AWS Pricing}},
url = {https://aws.amazon.com/pricing/services/}
}
@misc{Chronos,
title = {{Chronos}},
url = {https://mesos.github.io/chronos/}
}
@misc{IPython,
title = {{IPython}},
url = {https://ipython.org/}
}
@misc{OpenLava,
title = {{OpenLava}},
url = {http://www.openlava.org/}
}
@misc{CfnVPC,
title = {{CfnCluster Networking}},
url = {https://cfncluster.readthedocs.io/en/latest/networking.html}
}
@misc{SQS,
title = {{Amazon SQS}},
url = {https://aws.amazon.com/sqs/}
}
@misc{Cron,
title = {{Cron}},
url = {https://en.wikipedia.org/wiki/Cron}
}
@misc{MesosArch,
author = {Nathan, Paco},
title = {{Datacenter Computing with Apache Mesos}},
url = {http://www.slideshare.net/pacoid/datacenter-computing-with-apache-mesos},
year = {2014}
}
@misc{DCOS,
title = {{Mesosphere DC/OS}},
url = {https://dcos.io/}
}
@misc{Mesos,
title = {{Mesos}},
url = {https://mesos.apache.org/}
}
@article{Leclaire2016,
author = {Passerat-Palmbach, Jonathan and Reuillon, Romain and Leclaire, Mathieu and Makropoulos, Antonios and Robinson, Emma and Parisot, Sarah and Rueckert, Daniel},
file = {:Users/adrian/Work/project/papers/Large-scale neuroimaging studies with the OpenMOLE pipeline engine.pdf:pdf},
keywords = {high performance computing,large datasets,neuroimaging,parameter exploration,pipeline,reproducibility,workflow systems},
title = {{Large-scale neuroimaging studies with the OpenMOLE pipeline engine}},
year = {2016}
}
@misc{ScalaActors,
title = {{Scala Actors}},
url = {http://www.scala-lang.org/old/node/242}
}
@misc{Docker,
title = {{Docker}},
url = {https://www.docker.com/}
}
@article{SAGA,
abstract = {This document specifies the core components for the Simple API for$\backslash$nGrid Applications (SAGA Core API), a high level, application-oriented$\backslash$nAPI for grid application development. The scope of this API is derived$\backslash$nfrom the requirements$\backslash$n$\backslash$nspecified in GFD.71 ("A Requirements Analysis for a Simple API for$\backslash$nGrid applications"). It will in the future be extended by additional$\backslash$nAPI extensions.},
author = {{Open Grid Forum}},
file = {:Users/adrian/Work/project/papers/A Simple API for Grid Applications - SAGA.pdf:pdf},
pages = {324},
title = {{A Simple API for Grid Applications (SAGA)}},
url = {http://www.ogf.org/documents/GFD.90.pdf},
volume = {71},
year = {2007}
}
@misc{DRMAA,
title = {{DRMAA}},
url = {https://www.drmaa.org/}
}
@misc{OGF,
title = {{OGF}},
url = {https://www.ogf.org/}
}
@misc{OSGi,
title = {{OSGi}},
url = {https://www.osgi.org/}
}
@article{Cake,
author = {Harrison, Mark},
title = {{Cake pattern in depth}},
url = {http://www.cakesolutions.net/teamblogs/2011/12/19/cake-pattern-in-depth},
year = {2011}
}
@misc{SSHJ,
title = {{SSHJ}},
url = {https://github.com/hierynomus/sshj}
}
@misc{AWSCredentials,
title = {{AWS Security Credentials}},
url = {https://docs.aws.amazon.com/general/latest/gr/getting-aws-sec-creds.html}
}
@article{Preemptible,
title = {{GCE Preemptible VM Instances}},
url = {https://cloud.google.com/compute/docs/instances/preemptible}
}
@misc{Connectome,
title = {{The Human Connectome AWS Pipeline}},
url = {https://goo.gl/x5YLvf}
}
@misc{TavernaAWS,
title = {{Taverna AWS Setup}},
url = {https://wiki.biovel.eu/display/doc/Taverna+Server+AMI{\#}TavernaServerAMI-Furtherinformation}
}
@misc{GalaxyAWS,
title = {{Galaxy CloudMan AWS Setup}},
url = {https://wiki.galaxyproject.org/CloudMan/AWS/GettingStarted}
}
@misc{RandFor,
title = {{Random Forest}},
url = {https://en.wikipedia.org/wiki/Random{\_}forest}
}
